\chapter{Conclusions and Future Work}
\label{cha:7th_chapter}
In this chapter we make our final considerations about this work: first by reporting our conclusions in Section \ref{sec:conclusions}, then by discussing the open problems and the possible applications in which the framework presented could be used (Section \ref{sec:future_work}).

\section{Conclusions}
\label{sec:conclusions}


In Chapter \ref{cha:5th_chapter} we showed the results obtained by using Generative Adversarial Networks to synthesize missing modalities after training the models with thousands of brain MRI slices: the generated images are highly accurate and realistic, compared to sequences belonging to the dataset, and in many cases it is objectively difficult to distinguish between true and fake images.

Because of this we are overall satisfied by the generation quality of the images and by the achieved results (measured by the different evaluation metrics implemented) that are extremely encouraging for future develops and demonstrate the applicability of \ac{GAN}s in neuroimaging. 
In Chapter \ref{cha:6th_chapter}, then, we also showed, through various experiments on the trained models, the effectiveness of the skip connections, crucial to recover spatial information otherwise lost in the downsampling part of the Generator network.

We found cases where the image wasn't a realistic copy of the ground truth, but not due to some bad implementation choices but because the missing modality generated is originally obtained using a contrast agent and so it has a highly specific information difficult to reproduce and not present in any other sequence. 

However, the models implemented are far from being perfect with the generated sequences that in some cases contained blurred artifacts or low-level details not perfectly defined.

\vspace{5mm}
In general, the multi-modal models tested have proved to be better than unimodal \ac{GAN}s (except in the case in which target and input images present highly similar characteristics), due to the fact that they can exploit the correlation between available sequences, allowing us to reduce the order of magnitude of required models (from 12 single-input single-output to 4 multi-input single-output). The results obtained in this work demonstrate the possibility of using successfully this generative framework as a part of a bigger pipeline that can generate and then segment the synthesized missing modality, giving to the doctors an additional aid for the diagnosis of brain tumors.
\section{Future Work}
\label{sec:future_work}
In this section we describe the open problems encountered during the work and we propose different solutions to improve the system designed and to make possible, in the future, its employment in medical imaging.

\subsection{Open Problems}
\label{subsec:open_problems}
%\vspace{6mm} 
\noindent\textbf{Data Availability}

\vspace{2mm}
\noindent The amount of data available is crucial for any deep learning setting and the scarcity of annotated samples represents a huge problem, especially, for all the systems working in the medical imaging domain. In our case, the first problem we had to deal with, working with a medical dataset, was that BRATS2015, built for a segmentation challenge, was composed by two parts: one intended for the training and one for the testing, without annotated and segmented samples. So we could use only the first set of data, since we needed ground truths to evaluate the tumor area and to assess the quality of the segmentation obtained with the \ac{GAN} predictions.

The second problem we faced was that our reduced dataset is composed by 35.072 slices per modality (with 28.160 used for the training) but all these images belong to the volumes of 274 subjects (training set reduced to 219 patients), so the samples in the dataset are not independent and most of these slices contain very similar information.

\vspace{6mm} 
\noindent\textbf{Evaluation Metrics}

\vspace{2mm}
\noindent 
Another common and open problem is the one related to evaluation of the results produced by a Generative Adversarial Network: many works, and so did we, adopt metrics such as PSNR and SSIM to quantitatively evaluate the generated image but the problem is that these measures don't correspond to the visual quality of the image. 

GAN evaluation is not a settled issue yet and researchers suggest to validate the quality of the prediction by using segmentation models, as we did in Subsection \ref{subsec:segmentation_results}, or, even better, to recruit domain experts that could evaluate the results generated by the network: this, unfortunately, is not always accomplishable since it is expensive and time-consuming \cite{Yi_2019}.

\subsection{Possible Applications and Future Develops}
\label{sec:possible_applications}
\vspace{6mm} 
\noindent\textbf{Improving the MSE and PSNR implemented }

\vspace{2mm}
\noindent 
In our work we calculated the MSE and PSNR over the whole image, considering the pixels belonging to the brain as well as the ones with zero value. The reasoning behind is that the \ac{GAN} learns to generate also the black pixels so it is not wrong to measure the similarity and the error over the overall area. 

An alternative approach could be to modify the MSE and the PSNR implementation considering only the pixels with value different from zero and the ones not belonging to the tumor: by doing this it would be possible to understand, through a direct comparison, if the generation quality in the malignant area is higher/equal/lower with respect to the rest of the brain.

\vspace{6mm} 
\noindent\textbf{Tweaking the model}

\vspace{2mm}
\noindent 
In our case we used the hyperparameters values defined by \cite{pix2pix} and \cite{migan}, since we couldn't find any improvements over the defined values. We believe that networks capabilities can be increased by tweaking the model to find the optimal parameters. 


\vspace{6mm} 
\noindent\textbf{Variable number of inputs to the multi-modal model}

\vspace{2mm}
\noindent 
One way to improve the multi-modal networks developed would be to train them to synthesize one image in the presence of a variable numbers of input sequences (while in our case, we need to use the slices from all the three different modalities, in order to be able to synthesize the missing image).

\vspace{6mm} 
\noindent\textbf{Multi-input Multi-output model}

\vspace{2mm}
\noindent 
It would be interesting, then, to study possible improvements in the direction of multi-input multi-output models, where some researchers have already started to experiment with, such as Sharma et al. with their proposed MM-GAN \cite{migan}.
\newpage
\vspace{6mm} 
\noindent\textbf{Possible Applications}

\vspace{2mm}
\noindent The most obvious application of our work, as discussed in previous sections, would be to use the developed network as a part of a bigger pipeline of downstream analysis, such as segmentation, in order to improve the daily workflow of the radiologists. Some segmentation models indeed depend on the implicit assumption that all the input sequences are available: because of this, if some modalities, due to various reasons, are missing, then a generative adversarial network trained on brain \ac{MRI} would be very useful to synthesize the images needed.

This generative framework has many possible applications in different medical settings and lots of studies have been focusing on how to get the most from these networks. For instance, \ac{GAN}s would be very useful in \ac{MRI} image restoration where artifacts due to errors/motions during the scan can be removed, avoiding to repeat the exams multiple times. However, it's important to underline that, as Yi et al. suggests in \cite{Yi_2019}, \ac{GAN}-based methods are still far from being adopted clinically: this field is still in its infancy and a lot of work has to be done yet.